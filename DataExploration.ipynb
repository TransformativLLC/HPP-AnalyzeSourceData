{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T15:35:31.179045Z",
     "start_time": "2025-08-12T15:35:31.175374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "ad0e43886ca794f0",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T15:35:32.098020Z",
     "start_time": "2025-08-12T15:35:32.089266Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv();"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T15:35:37.453025Z",
     "start_time": "2025-08-12T15:35:36.077789Z"
    }
   },
   "cell_type": "code",
   "source": "from source_file_utils import get_source_file_names",
   "id": "c92137384f960577",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T17:12:50.865483Z",
     "start_time": "2025-08-12T17:12:50.816728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from functools import wraps\n",
    "import re\n",
    "from typing import Any, Callable, Dict, List, Mapping, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Exceptions\n",
    "# ---------------------------\n",
    "\n",
    "class AnalyzerError(RuntimeError):\n",
    "    \"\"\"Base class for analyzer errors.\"\"\"\n",
    "\n",
    "\n",
    "class ConfigurationError(AnalyzerError):\n",
    "    \"\"\"Raised for invalid analyzer configuration.\"\"\"\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Configuration & Reports\n",
    "# ---------------------------\n",
    "\n",
    "class ForeignKeySpec(BaseModel):\n",
    "    \"\"\"Declare a foreign key relationship for referential integrity checking.\"\"\"\n",
    "    child_table: str = Field(..., description=\"Table with the foreign key.\")\n",
    "    child_column: str = Field(..., description=\"Column in child that references a parent key.\")\n",
    "    parent_table: str = Field(..., description=\"Referenced table.\")\n",
    "    parent_column: str = Field(..., description=\"Primary/unique key column in the parent table.\")\n",
    "\n",
    "\n",
    "# class AnalyzerConfig(BaseModel):\n",
    "#     \"\"\"Configuration for the DataQualityAnalyzer.\"\"\"\n",
    "#     sample_rows: Optional[int] = Field(\n",
    "#         None,\n",
    "#         description=\"Row count to sample per table for expensive checks. None = full table.\"\n",
    "#     )\n",
    "#     duplicate_key_hints: List[str] = Field(\n",
    "#         default_factory=lambda: [\"id\", \"code\", \"number\", \"email\", \"sku\", \"name\"],\n",
    "#         description=\"Substrings used to discover likely identifier-like columns.\"\n",
    "#     )\n",
    "#     string_format_checks: List[str] = Field(\n",
    "#         default_factory=lambda: [\"date\", \"int_like\", \"float_like\", \"email\", \"phone\", \"uuid\", \"iso_datetime\", \"zip\"],\n",
    "#         description=\"String format classifiers to run.\"\n",
    "#     )\n",
    "#     outlier_method: str = Field(\n",
    "#         default=\"iqr\",\n",
    "#         description=\"Numeric outlier method: 'iqr' or 'zscore'.\"\n",
    "#     )\n",
    "#     z_threshold: float = Field(default=3.5, ge=0)\n",
    "#     iqr_multiplier: float = Field(default=1.5, ge=0)\n",
    "#     max_top_values: int = Field(default=10, ge=1)\n",
    "#     fk_specs: List[ForeignKeySpec] = Field(default_factory=list)\n",
    "#\n",
    "#     @field_validator(\"outlier_method\")\n",
    "#     def _validate_outlier_method(cls, v: str) -> str:\n",
    "#         v = v.lower()\n",
    "#         if v not in {\"iqr\", \"zscore\"}:\n",
    "#             raise ConfigurationError(\"outlier_method must be 'iqr' or 'zscore'\")\n",
    "#         return v\n",
    "\n",
    "class AnalyzerConfig(BaseModel):\n",
    "    \"\"\"Configuration for the DataQualityAnalyzer.\"\"\"\n",
    "    sample_rows: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Row count to sample per table for expensive checks. None = full table.\"\n",
    "    )\n",
    "    duplicate_key_hints: List[str] = Field(\n",
    "        default_factory=lambda: [\"id\", \"code\", \"number\", \"email\", \"sku\", \"name\", \"account\", \"invoice\", \"order\", \"serial\", \"company\", \"customer\", \"vendor\"],\n",
    "        description=\"Substrings used to discover likely identifier-like columns.\"\n",
    "    )\n",
    "    string_format_checks: List[str] = Field(\n",
    "        default_factory=lambda: [\"date\", \"int_like\", \"float_like\", \"email\", \"phone\", \"uuid\", \"iso_datetime\", \"zip\"],\n",
    "        description=\"String format classifiers to run.\"\n",
    "    )\n",
    "    outlier_method: str = Field(\n",
    "        default=\"iqr\",\n",
    "        description=\"Numeric outlier method: 'iqr' or 'zscore'.\"\n",
    "    )\n",
    "    z_threshold: float = Field(default=3.5, ge=0)\n",
    "    iqr_multiplier: float = Field(default=1.5, ge=0)\n",
    "    max_top_values: int = Field(default=10, ge=1)\n",
    "\n",
    "    # NEW: Explicit per-table uniqueness expectations.\n",
    "    # If provided for a table, these take precedence over heuristic hints.\n",
    "    unique_columns: Dict[str, List[Union[str, List[str]]]] = Field(\n",
    "        default_factory=dict,\n",
    "        description=(\n",
    "            \"Mapping: table_name -> list of columns or column-lists expected to be unique. \"\n",
    "            \"Each element can be a string (single col) or a list of strings (composite key).\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fk_specs: List[ForeignKeySpec] = Field(default_factory=list)\n",
    "\n",
    "    @field_validator(\"outlier_method\")\n",
    "    def _validate_outlier_method(cls, v: str) -> str:\n",
    "        v = v.lower()\n",
    "        if v not in {\"iqr\", \"zscore\"}:\n",
    "            raise ConfigurationError(\"outlier_method must be 'iqr' or 'zscore'\")\n",
    "        return v\n",
    "\n",
    "\n",
    "class ColumnProfile(BaseModel):\n",
    "    column: str\n",
    "    dtype: str\n",
    "    non_null: int\n",
    "    null_pct: float\n",
    "    unique: int\n",
    "    constant: bool\n",
    "    avg_len: Optional[float] = None\n",
    "    pct_empty_str: Optional[float] = None\n",
    "    pct_whitespace_str: Optional[float] = None\n",
    "    min_val: Optional[float] = None\n",
    "    max_val: Optional[float] = None\n",
    "    example_values: List[str] = Field(default_factory=list)\n",
    "\n",
    "\n",
    "class ColumnIssues(BaseModel):\n",
    "    column: str\n",
    "    has_mixed_types: bool = False\n",
    "    detected_formats: Dict[str, float] = Field(default_factory=dict)  # format -> coverage %\n",
    "    case_variants: Optional[List[str]] = None  # for likely categories\n",
    "\n",
    "\n",
    "class DuplicateReport(BaseModel):\n",
    "    exact_row_duplicates: int\n",
    "    near_text_duplicates: Dict[str, int]  # column -> count (normalized by stripping/punct/case)\n",
    "    candidate_key_dupes: Dict[str, int]   # column -> count of duplicate keys\n",
    "\n",
    "\n",
    "class OutlierReport(BaseModel):\n",
    "    method: str\n",
    "    counts_by_column: Dict[str, int]  # numeric column -> outlier count\n",
    "\n",
    "\n",
    "class FKIssue(BaseModel):\n",
    "    spec: ForeignKeySpec\n",
    "    missing_fk_count: int\n",
    "\n",
    "\n",
    "class TableReport(BaseModel):\n",
    "    table: str\n",
    "    rows: int\n",
    "    cols: int\n",
    "    column_profiles: List[ColumnProfile]\n",
    "    column_issues: List[ColumnIssues]\n",
    "    duplicates: DuplicateReport\n",
    "    outliers: OutlierReport\n",
    "    notes: List[str] = Field(default_factory=list)\n",
    "    # NEW: capture the actual duplicate rows (full DF)\n",
    "    exact_row_duplicate_rows: Optional[pd.DataFrame] = None\n",
    "\n",
    "    # allow DataFrame as a field\n",
    "    model_config = {'arbitrary_types_allowed': True}\n",
    "\n",
    "\n",
    "class AnalysisResult(BaseModel):\n",
    "    summary: pd.DataFrame  # table-level summary\n",
    "    tables: Dict[str, TableReport]\n",
    "    fk_issues: List[FKIssue] = Field(default_factory=list)\n",
    "    model_config = {'arbitrary_types_allowed': True}\n",
    "\n",
    "    def to_excel(self, path: str) -> None:\n",
    "        \"\"\"Write the full analysis as a multi-sheet Excel workbook.\"\"\"\n",
    "        with pd.ExcelWriter(path, engine=\"xlsxwriter\") as xw:\n",
    "            self.summary.to_excel(xw, sheet_name=\"summary\", index=False)\n",
    "            for tname, trep in self.tables.items():\n",
    "                # existing sheets...\n",
    "                pd.DataFrame([p.model_dump() for p in trep.column_profiles]).to_excel(\n",
    "                    xw, sheet_name=f\"{tname[:25]}_profiles\", index=False\n",
    "                )\n",
    "                pd.DataFrame([i.model_dump() for i in trep.column_issues]).to_excel(\n",
    "                    xw, sheet_name=f\"{tname[:25]}_issues\", index=False\n",
    "                )\n",
    "                # duplicates summary (existing)\n",
    "                dup_df = pd.DataFrame(\n",
    "                    {\"metric\": [\"exact_row_duplicates\"], \"value\": [trep.duplicates.exact_row_duplicates]}\n",
    "                )\n",
    "                # ... existing concat logic for near_text/candidate_key_dupes ...\n",
    "                dup_df.to_excel(xw, sheet_name=f\"{tname[:25]}_dupes\", index=False)\n",
    "\n",
    "                # NEW: full rows for exact duplicates (if any)\n",
    "                if trep.exact_row_duplicate_rows is not None and not trep.exact_row_duplicate_rows.empty:\n",
    "                    trep.exact_row_duplicate_rows.to_excel(\n",
    "                        xw, sheet_name=f\"{tname[:25]}_row_dupes\", index=False\n",
    "                    )\n",
    "\n",
    "                # outliers (existing)\n",
    "                out_df = pd.DataFrame(\n",
    "                    [{\"column\": c, \"outlier_count\": n, \"method\": trep.outliers.method}\n",
    "                     for c, n in trep.outliers.counts_by_column.items()]\n",
    "                )\n",
    "                out_df.to_excel(xw, sheet_name=f\"{tname[:25]}_outliers\", index=False)\n",
    "\n",
    "\n",
    "            if self.fk_issues:\n",
    "                pd.DataFrame(\n",
    "                    [\n",
    "                        {\n",
    "                            \"child_table\": i.spec.child_table,\n",
    "                            \"child_column\": i.spec.child_column,\n",
    "                            \"parent_table\": i.spec.parent_table,\n",
    "                            \"parent_column\": i.spec.parent_column,\n",
    "                            \"missing_fk_count\": i.missing_fk_count,\n",
    "                        }\n",
    "                        for i in self.fk_issues\n",
    "                    ]\n",
    "                ).to_excel(xw, sheet_name=\"fk_issues\", index=False)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Check registry (pluggable)\n",
    "# ---------------------------\n",
    "\n",
    "CheckFn = Callable[[str, pd.DataFrame, AnalyzerConfig], Dict[str, Any]]\n",
    "_CHECKS: List[CheckFn] = []\n",
    "\n",
    "\n",
    "def register_check(fn: CheckFn) -> CheckFn:\n",
    "    \"\"\"Decorator to register a table-level check producing a dict payload.\"\"\"\n",
    "    @wraps(fn)\n",
    "    def _wrapped(table: str, df: pd.DataFrame, cfg: AnalyzerConfig) -> Dict[str, Any]:\n",
    "        return fn(table, df, cfg)\n",
    "    _CHECKS.append(_wrapped)\n",
    "    return _wrapped\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Helpers\n",
    "# ---------------------------\n",
    "\n",
    "_STRIP_PUNCT_RE = re.compile(r\"[^\\w\\s]\", flags=re.UNICODE)\n",
    "\n",
    "\n",
    "def _maybe_sample(df: pd.DataFrame, n: Optional[int]) -> pd.DataFrame:\n",
    "    if n is None or len(df) <= n:\n",
    "        return df\n",
    "    return df.sample(n=n, random_state=42)\n",
    "\n",
    "\n",
    "def _try_parse_datetime(s: pd.Series) -> pd.Series:\n",
    "    return pd.to_datetime(s, errors=\"coerce\")\n",
    "\n",
    "\n",
    "def _is_int_like(s: pd.Series) -> pd.Series:\n",
    "    return s.str.fullmatch(r\"[+-]?\\d+\", na=False)\n",
    "\n",
    "\n",
    "def _is_float_like(s: pd.Series) -> pd.Series:\n",
    "    return s.str.fullmatch(r\"[+-]?(\\d+(\\.\\d+)?|\\.\\d+)\", na=False)\n",
    "\n",
    "\n",
    "def _is_email(s: pd.Series) -> pd.Series:\n",
    "    return s.str.fullmatch(r\"[^@\\s]+@[^@\\s]+\\.[^@\\s]+\", na=False)\n",
    "\n",
    "\n",
    "def _is_phone(s: pd.Series) -> pd.Series:\n",
    "    return s.str.fullmatch(r\"(\\+?\\d{1,3}[\\s.-]?)?\\(?\\d{2,4}\\)?[\\s.-]?\\d{3,4}[\\s.-]?\\d{3,4}\", na=False)\n",
    "\n",
    "\n",
    "def _is_uuid(s: pd.Series) -> pd.Series:\n",
    "    return s.str.fullmatch(r\"[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[1-5][0-9a-fA-F]{3}-[89abAB][0-9a-fA-F]{3}-[0-9a-fA-F]{12}\", na=False)\n",
    "\n",
    "\n",
    "def _is_iso_datetime(s: pd.Series) -> pd.Series:\n",
    "    return s.str.fullmatch(r\"\\d{4}-\\d{2}-\\d{2}(T|\\s)\\d{2}:\\d{2}(:\\d{2})?(\\.\\d+)?(Z|[+-]\\d{2}:\\d{2})?\", na=False)\n",
    "\n",
    "\n",
    "def _is_zip(s: pd.Series) -> pd.Series:\n",
    "    return s.str.fullmatch(r\"\\d{5}(-\\d{4})?\", na=False)\n",
    "\n",
    "\n",
    "_FORMATTERS: Dict[str, Callable[[pd.Series], pd.Series]] = {\n",
    "    \"date\": lambda s: _try_parse_datetime(s).notna(),\n",
    "    \"int_like\": _is_int_like,\n",
    "    \"float_like\": _is_float_like,\n",
    "    \"email\": _is_email,\n",
    "    \"phone\": _is_phone,\n",
    "    \"uuid\": _is_uuid,\n",
    "    \"iso_datetime\": _is_iso_datetime,\n",
    "    \"zip\": _is_zip,\n",
    "}\n",
    "\n",
    "\n",
    "def _normalize_text_for_dupe(s: pd.Series) -> pd.Series:\n",
    "    s2 = s.astype(str).str.lower().str.strip()\n",
    "    s2 = s2.str.replace(_STRIP_PUNCT_RE, \"\", regex=True).str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    return s2\n",
    "\n",
    "\n",
    "def _iqr_outliers(x: pd.Series, k: float = 1.5) -> pd.Series:\n",
    "    q1 = x.quantile(0.25)\n",
    "    q3 = x.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    low, high = q1 - k * iqr, q3 + k * iqr\n",
    "    return (x < low) | (x > high)\n",
    "\n",
    "\n",
    "def _zscore_outliers(x: pd.Series, z: float = 3.5) -> pd.Series:\n",
    "    mu = x.mean()\n",
    "    sigma = x.std(ddof=0)\n",
    "    if sigma == 0 or np.isnan(sigma):\n",
    "        return pd.Series(False, index=x.index)\n",
    "    return (np.abs((x - mu) / sigma) > z)\n",
    "\n",
    "\n",
    "def _top_examples(s: pd.Series, k: int) -> List[str]:\n",
    "    vc = s.dropna().astype(str).head(10000).value_counts(dropna=False)\n",
    "    return [str(v) for v in vc.head(k).index.tolist()]\n",
    "\n",
    "\n",
    "def _likely_identifier_columns(df: pd.DataFrame, hints: List[str]) -> List[str]:\n",
    "    cols = []\n",
    "    for c in df.columns:\n",
    "        lc = c.lower()\n",
    "        if any(h in lc for h in hints):\n",
    "            cols.append(c)\n",
    "    return cols\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Checks\n",
    "# ---------------------------\n",
    "\n",
    "@register_check\n",
    "def profile_columns(table: str, df: pd.DataFrame, cfg: AnalyzerConfig) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Column-level profiling: dtype, missingness, unique counts, constant columns,\n",
    "    numeric min/max, string length stats, empty/whitespace ratio, examples.\n",
    "    \"\"\"\n",
    "    profiles: List[ColumnProfile] = []\n",
    "    sample = _maybe_sample(df, cfg.sample_rows)\n",
    "\n",
    "    for c in df.columns:\n",
    "        s = sample[c]\n",
    "        dtype = str(df[c].dtype)\n",
    "        non_null = int(s.notna().sum())\n",
    "        null_pct = float((s.isna().mean() * 100.0))\n",
    "        unique = int(s.nunique(dropna=True))\n",
    "        constant = unique <= 1\n",
    "\n",
    "        avg_len = pct_empty = pct_ws = None\n",
    "        min_val = max_val = None\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(df[c]):\n",
    "            min_val = float(pd.to_numeric(s, errors=\"coerce\").min(skipna=True)) if non_null else None\n",
    "            max_val = float(pd.to_numeric(s, errors=\"coerce\").max(skipna=True)) if non_null else None\n",
    "        elif pd.api.types.is_string_dtype(df[c]) or df[c].dtype == \"object\":\n",
    "            s_str = s.dropna().astype(str)\n",
    "            if not s_str.empty:\n",
    "                lengths = s_str.str.len()\n",
    "                avg_len = float(lengths.mean())\n",
    "                pct_empty = float((s_str == \"\").mean() * 100.0)\n",
    "                pct_ws = float((s_str.str.fullmatch(r\"\\s*\").mean()) * 100.0)\n",
    "\n",
    "        profiles.append(\n",
    "            ColumnProfile(\n",
    "                column=c,\n",
    "                dtype=dtype,\n",
    "                non_null=non_null,\n",
    "                null_pct=round(null_pct, 3),\n",
    "                unique=unique,\n",
    "                constant=constant,\n",
    "                avg_len=avg_len,\n",
    "                pct_empty_str=pct_empty,\n",
    "                pct_whitespace_str=pct_ws,\n",
    "                min_val=min_val,\n",
    "                max_val=max_val,\n",
    "                example_values=_top_examples(s, cfg.max_top_values),\n",
    "            )\n",
    "        )\n",
    "    return {\"column_profiles\": profiles}\n",
    "\n",
    "\n",
    "@register_check\n",
    "def detect_type_and_format_issues(table: str, df: pd.DataFrame, cfg: AnalyzerConfig) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Detect mixed types in object-like columns and estimate format coverage (emails, phones, dates, etc.).\n",
    "    Also report case variants for likely categorical fields.\n",
    "    \"\"\"\n",
    "    issues: List[ColumnIssues] = []\n",
    "    sample = _maybe_sample(df, cfg.sample_rows)\n",
    "\n",
    "    for c in df.columns:\n",
    "        s = sample[c]\n",
    "        col_issue = ColumnIssues(column=c)\n",
    "\n",
    "        # Mixed types detection\n",
    "        if df[c].dtype == \"object\":\n",
    "            pytypes = s.dropna().map(type)\n",
    "            if not pytypes.empty:\n",
    "                counts = pytypes.value_counts()\n",
    "                col_issue.has_mixed_types = counts.shape[0] > 1\n",
    "\n",
    "        # String format checks\n",
    "        if pd.api.types.is_string_dtype(df[c]) or df[c].dtype == \"object\":\n",
    "            s_str = s.dropna().astype(str)\n",
    "            detected: Dict[str, float] = {}\n",
    "            for name in cfg.string_format_checks:\n",
    "                fn = _FORMATTERS.get(name)\n",
    "                if fn and not s_str.empty:\n",
    "                    m = fn(s_str)\n",
    "                    detected[name] = round(float(m.mean() * 100.0), 2)\n",
    "            col_issue.detected_formats = detected\n",
    "\n",
    "            # Case-variant categories (heuristic): low-cardinality textual columns\n",
    "            nunique = s_str.nunique(dropna=True)\n",
    "            if 1 < nunique <= 50:\n",
    "                lower_map = s_str.str.strip().str.lower().value_counts()\n",
    "                if lower_map.shape[0] < nunique:\n",
    "                    # same tokens differing by case/space exist\n",
    "                    col_issue.case_variants = _top_examples(s_str, cfg.max_top_values)\n",
    "\n",
    "        issues.append(col_issue)\n",
    "\n",
    "    return {\"column_issues\": issues}\n",
    "\n",
    "\n",
    "# @register_check\n",
    "# def duplicate_scans(table: str, df: pd.DataFrame, cfg: AnalyzerConfig) -> Dict[str, Any]:\n",
    "#     \"\"\"\n",
    "#     Exact row duplicates, normalized near-duplicates for text columns,\n",
    "#     and duplicate counts for likely identifier-like columns.\n",
    "#     \"\"\"\n",
    "#     sample = _maybe_sample(df, cfg.sample_rows)\n",
    "#     # Exact row duplicates\n",
    "#     exact_dupes = int(sample.duplicated().sum())\n",
    "#\n",
    "#     # Near text duplicates per column (case/space/punct normalized)\n",
    "#     near_text_dupes: Dict[str, int] = {}\n",
    "#     for c in sample.columns:\n",
    "#         if pd.api.types.is_string_dtype(df[c]) or df[c].dtype == \"object\":\n",
    "#             s_norm = _normalize_text_for_dupe(sample[c].fillna(\"\"))\n",
    "#             dups = int(s_norm.duplicated().sum())\n",
    "#             if dups > 0:\n",
    "#                 near_text_dupes[c] = dups\n",
    "#\n",
    "#     # Candidate key dupes\n",
    "#     candidate_key_dupes: Dict[str, int] = {}\n",
    "#     for c in _likely_identifier_columns(df, cfg.duplicate_key_hints):\n",
    "#         dups = int(sample[c].duplicated(keep=False).sum()) if c in sample.columns else 0\n",
    "#         if dups > 0:\n",
    "#             candidate_key_dupes[c] = dups\n",
    "#\n",
    "#     return {\n",
    "#         \"duplicates\": DuplicateReport(\n",
    "#             exact_row_duplicates=exact_dupes,\n",
    "#             near_text_duplicates=near_text_dupes,\n",
    "#             candidate_key_dupes=candidate_key_dupes,\n",
    "#         )\n",
    "#     }\n",
    "\n",
    "\n",
    "@register_check\n",
    "def duplicate_scans(table: str, df: pd.DataFrame, cfg: AnalyzerConfig) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Duplicates scoped to columns expected to be unique + exact row duplicates.\n",
    "    - Exact full-row duplicates are computed on the full table (not sampled).\n",
    "    - Candidate key dupes and near-text dupes use explicit/inferred unique specs.\n",
    "      A unique spec can be a single column 'col' or a list ['col1','col2'] for composite uniqueness.\n",
    "    \"\"\"\n",
    "    # 1) Exact full-row duplicates on FULL DF (linear time)\n",
    "    exact_mask = df.duplicated(keep=False)\n",
    "    exact_dupes = int(exact_mask.sum())\n",
    "    exact_rows_df = df.loc[exact_mask].copy()\n",
    "\n",
    "    # 2) For column-wise checks, honor sampling if configured\n",
    "    sample = _maybe_sample(df, cfg.sample_rows)\n",
    "\n",
    "    # 3) Resolve uniqueness specs\n",
    "    explicit_specs = cfg.unique_columns.get(table, [])\n",
    "    if explicit_specs:  # user-provided: may include single columns or lists for composite keys\n",
    "        specs = explicit_specs\n",
    "    else:\n",
    "        # fallback: infer single-column candidates by name hints\n",
    "        specs = _likely_identifier_columns(df, cfg.duplicate_key_hints)\n",
    "\n",
    "    candidate_key_dupes: Dict[str, int] = {}\n",
    "    near_text_dupes: Dict[str, int] = {}\n",
    "\n",
    "    for spec in specs:\n",
    "        if isinstance(spec, str):\n",
    "            cols = [spec]\n",
    "            label = spec\n",
    "        else:\n",
    "            cols = list(spec)\n",
    "            label = \"+\".join(cols)\n",
    "\n",
    "        # skip if any column missing\n",
    "        if not cols or not all(c in df.columns for c in cols):\n",
    "            continue\n",
    "\n",
    "        # duplicate detection for the spec (single or composite)\n",
    "        dups = int(sample.duplicated(subset=cols, keep=False).sum())\n",
    "        if dups > 0:\n",
    "            candidate_key_dupes[label] = dups\n",
    "\n",
    "        # near-text duplicates only for single string-like columns\n",
    "        if len(cols) == 1:\n",
    "            c = cols[0]\n",
    "            if pd.api.types.is_string_dtype(df[c]) or df[c].dtype == \"object\":\n",
    "                s_norm = _normalize_text_for_dupe(sample[c].astype(str))\n",
    "                nd = int(s_norm.duplicated().sum())\n",
    "                if nd > 0:\n",
    "                    near_text_dupes[label] = nd\n",
    "\n",
    "    return {\n",
    "        \"duplicates\": DuplicateReport(\n",
    "            exact_row_duplicates=exact_dupes,\n",
    "            near_text_duplicates=near_text_dupes,\n",
    "            candidate_key_dupes=candidate_key_dupes,\n",
    "        ),\n",
    "        # pass the actual duplicate rows back for Excel export\n",
    "        \"exact_row_dupe_rows\": exact_rows_df,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "@register_check\n",
    "def numeric_outliers(table: str, df: pd.DataFrame, cfg: AnalyzerConfig) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Count numeric outliers per column using configured method.\n",
    "    \"\"\"\n",
    "    sample = _maybe_sample(df, cfg.sample_rows)\n",
    "    numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    counts: Dict[str, int] = {}\n",
    "    for c in numeric_cols:\n",
    "        x = pd.to_numeric(sample[c], errors=\"coerce\").dropna()\n",
    "        if x.empty:\n",
    "            counts[c] = 0\n",
    "            continue\n",
    "        if cfg.outlier_method == \"iqr\":\n",
    "            m = _iqr_outliers(x, cfg.iqr_multiplier)\n",
    "        else:\n",
    "            m = _zscore_outliers(x, cfg.z_threshold)\n",
    "        counts[c] = int(m.sum())\n",
    "\n",
    "    return {\"outliers\": OutlierReport(method=cfg.outlier_method, counts_by_column=counts)}\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Analyzer\n",
    "# ---------------------------\n",
    "\n",
    "class DataQualityAnalyzer:\n",
    "    \"\"\"Execute a suite of data-quality checks against pandas DataFrames.\"\"\"\n",
    "\n",
    "    def __init__(self, config: Optional[AnalyzerConfig] = None) -> None:\n",
    "        self.config = config or AnalyzerConfig()\n",
    "\n",
    "    def analyze(\n",
    "        self,\n",
    "        tables: Mapping[str, pd.DataFrame],\n",
    "    ) -> AnalysisResult:\n",
    "        \"\"\"Run all registered checks on each table and build an aggregate report.\n",
    "\n",
    "        Args:\n",
    "            tables: Mapping of table name -> DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            AnalysisResult containing table-level reports, summary, and FK issues (if any).\n",
    "        \"\"\"\n",
    "        table_reports: Dict[str, TableReport] = {}\n",
    "        summary_rows: List[Dict[str, Any]] = []\n",
    "\n",
    "        # Per-table checks\n",
    "        for tname, df in tables.items():\n",
    "            payload: Dict[str, Any] = {}\n",
    "            for check in _CHECKS:\n",
    "                payload.update(check(tname, df, self.config))\n",
    "\n",
    "            profiles: List[ColumnProfile] = payload[\"column_profiles\"]\n",
    "            issues: List[ColumnIssues] = payload[\"column_issues\"]\n",
    "            dupes: DuplicateReport = payload[\"duplicates\"]\n",
    "            outliers: OutlierReport = payload[\"outliers\"]\n",
    "            dup_rows_df: Optional[pd.DataFrame] = payload.get(\"exact_row_dupe_rows\")\n",
    "\n",
    "            report = TableReport(\n",
    "                table=tname,\n",
    "                rows=int(df.shape[0]),\n",
    "                cols=int(df.shape[1]),\n",
    "                column_profiles=profiles,\n",
    "                column_issues=issues,\n",
    "                duplicates=dupes,\n",
    "                outliers=outliers,\n",
    "                exact_row_duplicate_rows=dup_rows_df,  # NEW\n",
    "            )\n",
    "            table_reports[tname] = report\n",
    "\n",
    "            summary_rows.append(\n",
    "                {\n",
    "                    \"table\": tname,\n",
    "                    \"rows\": report.rows,\n",
    "                    \"cols\": report.cols,\n",
    "                    \"exact_row_dupes\": dupes.exact_row_duplicates,\n",
    "                    \"columns_with_near_text_dupes\": len(dupes.near_text_duplicates),\n",
    "                    \"columns_with_candidate_key_dupes\": len(dupes.candidate_key_dupes),\n",
    "                    \"numeric_columns_with_outliers\": sum(1 for v in outliers.counts_by_column.values() if v > 0),\n",
    "                    \"avg_null_pct\": np.mean([p.null_pct for p in profiles]) if profiles else np.nan,\n",
    "                    \"constant_columns\": sum(1 for p in profiles if p.constant),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Optional FK checks across tables\n",
    "        fk_issues: List[FKIssue] = []\n",
    "        if self.config.fk_specs:\n",
    "            for spec in self.config.fk_specs:\n",
    "                if spec.child_table not in tables or spec.parent_table not in tables:\n",
    "                    continue\n",
    "                child = tables[spec.child_table]\n",
    "                parent = tables[spec.parent_table]\n",
    "                if spec.child_column not in child.columns or spec.parent_column not in parent.columns:\n",
    "                    continue\n",
    "                child_keys = pd.Series(child[spec.child_column]).dropna().unique()\n",
    "                parent_keys = pd.Series(parent[spec.parent_column]).dropna().unique()\n",
    "                missing = ~pd.Series(child[spec.child_column]).isin(parent_keys)\n",
    "                missing_count = int(missing.sum())\n",
    "                if missing_count > 0:\n",
    "                    fk_issues.append(FKIssue(spec=spec, missing_fk_count=missing_count))\n",
    "\n",
    "        summary_df = pd.DataFrame(summary_rows).sort_values([\"rows\", \"table\"], ascending=[False, True], ignore_index=True)\n",
    "        return AnalysisResult(summary=summary_df, tables=table_reports, fk_issues=fk_issues)"
   ],
   "id": "344a016061cbd507",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T15:35:54.729621Z",
     "start_time": "2025-08-12T15:35:54.725869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "source_file_names = get_source_file_names()\n",
    "print(f\"{len(source_file_names)} source files retrieved.\")"
   ],
   "id": "b513a36b17a8c049",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 source files retrieved.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T17:32:38.999692Z",
     "start_time": "2025-08-12T17:32:37.523591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "i = 3\n",
    "df = pd.read_excel(source_file_names[i])"
   ],
   "id": "1e3acf0c3aea79ce",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T17:32:39.626931Z",
     "start_time": "2025-08-12T17:32:39.623015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "source_name = os.path.splitext(os.path.basename(source_file_names[i]))[0].replace(' ', '_')\n",
    "source_name"
   ],
   "id": "3344aea27a20152a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kle_CRM'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T17:32:42.939251Z",
     "start_time": "2025-08-12T17:32:41.567226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# drop empty rows\n",
    "df = df.dropna(how='all')\n",
    "df = df.loc[~(df.apply(lambda row: row.astype(str).str.strip().eq('').all(), axis=1))]"
   ],
   "id": "93b347ede895c010",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T17:33:50.242381Z",
     "start_time": "2025-08-12T17:33:48.597845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create config with defaults â€” no foreign keys\n",
    "cfg = AnalyzerConfig(\n",
    "    sample_rows=None,        # None = run checks on all rows\n",
    "    outlier_method=\"iqr\",    # can be \"iqr\" or \"zscore\"\n",
    "    unique_columns={source_name: [\n",
    "        \"__kp_Contact\",\n",
    "        # [\"first_name\", \"last_name\"]\n",
    "    ]}\n",
    ")\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = DataQualityAnalyzer(cfg)\n",
    "\n",
    "# Analyze the single table (name it anything you like)\n",
    "result = analyzer.analyze({source_name: df})\n",
    "\n",
    "# print summary to stdout\n",
    "# print(result.summary)\n",
    "\n",
    "# save the full report to Excel with multiple sheets\n",
    "result.to_excel(f\"dq_report_{source_name}.xlsx\")"
   ],
   "id": "88ab9a7d39225d88",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3cf4e31c18e96267"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
